{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Demonstration for WiMAE and ContraWiMAE\n",
    "\n",
    "- This notebook demonstrates how to train both WiMAE and ContraWiMAE models\n",
    "using real wireless channel data from the pretrain folder."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Imports and Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All imports successful!\n",
      "PyTorch version: 2.5.1\n",
      "CUDA available: True\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import torch\n",
    "import numpy as np\n",
    "import yaml\n",
    "from pathlib import Path\n",
    "\n",
    "# Add parent directory to path for imports\n",
    "try:\n",
    "    # For Python scripts\n",
    "    sys.path.append(str(Path(__file__).parent.parent))\n",
    "except NameError:\n",
    "    # For Jupyter notebooks\n",
    "    sys.path.append(str(Path().cwd().parent))\n",
    "\n",
    "# WiMAE imports\n",
    "from wimae.training.train_wimae import WiMAETrainer\n",
    "# from wimae.training.train_contramae import ContraWiMAETrainer\n",
    "# from wimae.models.base import WiMAE\n",
    "# from wimae.models.contramae import ContraWiMAE\n",
    "\n",
    "print(\"All imports successful!\")\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available datasets: 12 cities\n",
      "  • city_0_newyork_channels.npz: 10.0 MB\n",
      "  • city_10_austin_channels.npz: 14.5 MB\n",
      "  • city_13_columbus_channels.npz: 11.2 MB\n",
      "  • city_17_seattle_channels.npz: 11.5 MB\n",
      "  • city_1_losangeles_channels.npz: 5.8 MB\n",
      "  • city_2_chicago_channels.npz: 2.2 MB\n",
      "  • city_3_houston_channels.npz: 20.1 MB\n",
      "  • city_4_phoenix_channels.npz: 21.1 MB\n",
      "  • city_5_philadelphia_channels.npz: 4.9 MB\n",
      "  • city_6_miami_channels.npz: 13.1 MB\n",
      "  • city_8_dallas_channels.npz: 19.6 MB\n",
      "  • city_9_sanfrancisco_channels.npz: 13.0 MB\n",
      "\n",
      "Sample data structure from city_0_newyork_channels.npz:\n",
      "  • channels: (1283, 1, 32, 32) (complex64)\n",
      "  • name: () (<U14)\n",
      "  • n_rows: (2,) (int64)\n",
      "  • n_per_row: () (int64)\n",
      "  • active_bs: (1,) (int64)\n",
      "  • n_ant_bs: () (int64)\n",
      "  • n_ant_ue: () (int64)\n",
      "  • n_subcarriers: () (int64)\n",
      "  • scs: () (float64)\n",
      "  • data_folder: () (<U16)\n",
      "  • bs_rotation: (3,) (int64)\n",
      "  • enable_bs2bs: () (bool)\n",
      "  • num_paths: () (int64)\n"
     ]
    }
   ],
   "source": [
    "data_path = \"../data/pretrain\"\n",
    "npz_files = list(Path(data_path).glob(\"*.npz\"))\n",
    "\n",
    "print(f\"Available datasets: {len(npz_files)} cities\")\n",
    "for file in sorted(npz_files):\n",
    "    file_size = file.stat().st_size / (1024*1024)  # MB\n",
    "    print(f\"  • {file.name}: {file_size:.1f} MB\")\n",
    "\n",
    "# Load one file to check data structure\n",
    "with np.load(npz_files[0]) as sample_data:\n",
    "    print(f\"\\nSample data structure from {npz_files[0].name}:\")\n",
    "    for key, value in sample_data.items():\n",
    "        if hasattr(value, 'shape'):\n",
    "            print(f\"  • {key}: {value.shape} ({value.dtype})\")\n",
    "        else:\n",
    "            print(f\"  • {key}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Configuration Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configuration loaded successfully!\n",
      "Model type: wimae\n",
      "Encoder dimensions: 64\n",
      "Batch size: 64\n",
      "Training epochs: 3000\n",
      "Learning rate: 0.0003\n",
      "\n",
      "Adjusted for demo:\n",
      "Epochs: 1\n",
      "Batch size: 768\n",
      "Data directory: ../data/pretrain\n",
      "Mask ratio: 0.2\n",
      "Experiment folder name: demo_exp\n",
      "Debug data size: 3840\n"
     ]
    }
   ],
   "source": [
    "config_path = \"../configs/default_training.yaml\"\n",
    "with open(config_path, 'r') as f:\n",
    "    config = yaml.safe_load(f)\n",
    "\n",
    "print(\"Configuration loaded successfully!\")\n",
    "print(f\"Model type: {config['model']['type']}\")\n",
    "print(f\"Encoder dimensions: {config['model']['encoder_dim']}\")\n",
    "print(f\"Batch size: {config['training']['batch_size']}\")\n",
    "print(f\"Training epochs: {config['training']['epochs']}\")\n",
    "print(f\"Learning rate: {config['training']['optimizer']['lr']}\")\n",
    "\n",
    "# Adjust config for demo (shorter training)\n",
    "config['training']['epochs'] = 1\n",
    "config['training']['batch_size'] = 768\n",
    "config['data']['data_dir'] = \"../data/pretrain\"\n",
    "config['data']['debug_size'] = config['training']['batch_size'] * 5\n",
    "config['model']['mask_ratio'] = 0.2\n",
    "config['logging']['exp_name'] = \"demo_exp\"\n",
    "print(f\"\\nAdjusted for demo:\")\n",
    "print(f\"Epochs: {config['training']['epochs']}\")\n",
    "print(f\"Batch size: {config['training']['batch_size']}\")\n",
    "print(f\"Data directory: {config['data']['data_dir']}\")\n",
    "print(f\"Mask ratio: {config['model']['mask_ratio']}\")\n",
    "print(f\"Experiment folder name: {config['logging']['exp_name']}\")\n",
    "print(f\"Debug data size: {config['data']['debug_size']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### WiMAE Training Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting up WiMAE training...\n",
      "WiMAE trainer initialized\n",
      "WiMAE model created:\n",
      "  • model_type: WiMAE\n",
      "  • patch_size: (1, 16)\n",
      "  • encoder_dim: 64\n",
      "  • encoder_layers: 12\n",
      "  • encoder_nhead: 16\n",
      "  • decoder_layers: 4\n",
      "  • decoder_nhead: 8\n",
      "  • mask_ratio: 0.2\n",
      "  • total_parameters: 554128\n",
      "  • trainable_parameters: 554128\n"
     ]
    }
   ],
   "source": [
    "print(\"Setting up WiMAE training...\")\n",
    "\n",
    "# Create WiMAE trainer (model will be created during initialization)\n",
    "wimae_trainer = WiMAETrainer(config=config)\n",
    "\n",
    "print(\"WiMAE trainer initialized\")\n",
    "\n",
    "# Get model information\n",
    "wimae_info = wimae_trainer.model.get_model_info()\n",
    "print(f\"WiMAE model created:\")\n",
    "for key, value in wimae_info.items():\n",
    "    print(f\"  • {key}: {value}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  WiMAE Training Execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting WiMAE training...\n",
      "Total samples: 18824, dimensions: 32x32\n",
      "Loading file 1/12: city_0_newyork_channels.npz\n",
      "Loading file 2/12: city_1_losangeles_channels.npz\n",
      "Loading file 3/12: city_10_austin_channels.npz\n",
      "Loading file 4/12: city_9_sanfrancisco_channels.npz\n",
      "Loading file 5/12: city_6_miami_channels.npz\n"
     ]
    }
   ],
   "source": [
    "print(\"Starting WiMAE training...\")\n",
    "\n",
    "try:\n",
    "    # Start training (dataloaders will be set up automatically)\n",
    "    wimae_trainer.train()\n",
    "    print(\"WiMAE training completed successfully!\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Training failed: {e}\")\n",
    "    print(\"This is expected in a demo - check your data paths and configuration\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Checkpoints and Model Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Checkpoint Management\")\n",
    "print(\"=\" * 30)\n",
    "\n",
    "checkpoint_path = Path(f\"./{config['logging']['log_dir']}\") / f\"{config['model']['type']}_{config['logging']['exp_name']}\"\n",
    "\n",
    "# Check available checkpoints\n",
    "wimae_checkpoints = list(checkpoint_path.glob(\"*.pt\")) if checkpoint_path.exists() else []\n",
    "\n",
    "print(f\"WiMAE checkpoints: {len(wimae_checkpoints)}\")\n",
    "for ckpt in wimae_checkpoints:\n",
    "    print(f\"  • {ckpt.name}\")\n",
    "\n",
    "# Example of loading a checkpoint (if available)\n",
    "if wimae_checkpoints:\n",
    "    print(f\"\\nExample: Loading WiMAE checkpoint...\")\n",
    "    try:\n",
    "        checkpoint = torch.load(wimae_checkpoints[0], map_location='cpu')\n",
    "        print(f\"Loaded checkpoint from epoch {checkpoint.get('epoch', 'unknown')}\")\n",
    "        print(f\"Validation loss: {checkpoint.get('best_val_loss', 'unknown')}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to load checkpoint: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
