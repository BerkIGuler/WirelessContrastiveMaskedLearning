{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Demonstration for WiMAE and ContraWiMAE\n",
    "\n",
    "- This notebook demonstrates how to train both WiMAE and ContraWiMAE models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Imports and Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version: 2.5.1+cu121\n",
      "CUDA available: True\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import torch\n",
    "import numpy as np\n",
    "import yaml\n",
    "import pprint\n",
    "from pathlib import Path\n",
    "\n",
    "# For Jupyter notebooks\n",
    "sys.path.append(str(Path().cwd().parent))\n",
    "\n",
    "# WiMAE imports\n",
    "from contrawimae.training.train_wimae import WiMAETrainer\n",
    "from contrawimae.training.train_contramae import ContraWiMAETrainer\n",
    "\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available datasets: 5 cities\n",
      "  • boston5g_3p5_bs000.npz: 22.1 MB\n",
      "  • city_44_lisboa_3p5_bs000.npz: 66.6 MB\n",
      "  • city_50_edinburgh_3p5_bs000.npz: 63.8 MB\n",
      "  • city_5_philadelphia_3p5_bs001.npz: 60.7 MB\n",
      "  • city_66_bruxelles_3p5_bs000.npz: 42.8 MB\n",
      "\n",
      "Sample data structure from city_44_lisboa_3p5_bs000.npz:\n",
      "  • channels: (9283, 1, 32, 32) (complex64)\n",
      "  • rx_pos: [[ -11.6456 -112.351     1.5   ]\n",
      " [ -11.6456 -111.351     1.5   ]\n",
      " [ -11.6456 -110.351     1.5   ]\n",
      " ...\n",
      " [ -18.6456  131.649     1.5   ]\n",
      " [ -19.6456  132.649     1.5   ]\n",
      " [ -20.6456  133.649     1.5   ]]\n",
      "  • tx_pos: [[ 6.29055e-03 -8.95592e-02  1.00000e+01]]\n",
      "  • los: [0 0 0 ... 0 0 0]\n",
      "  • scenario_name: city_44_lisboa_3p5\n",
      "  • bs_index: 0\n",
      "  • scaling_factor: 1000000.0\n",
      "  • active_mask_original_indices: [14267 14529 14791 ... 78188 78449 78710]\n",
      "  • total_users_original: 87246\n",
      "  • active_users_count: 9283\n",
      "  • ch_params_info: {'subcarriers': 32, 'bandwidth': 960000, 'num_paths': 20, 'bs_antenna_shape': array([32,  1]), 'bs_antenna_rotation': array([   0,    0, -135])}\n",
      "  • beam_labels: [[ 4.  9. 19.]\n",
      " [ 4.  9. 19.]\n",
      " [ 4.  9. 19.]\n",
      " ...\n",
      " [12. 25. 49.]\n",
      " [12. 25. 49.]\n",
      " [12. 25. 49.]]\n",
      "  • beam_calculation_info: {'beam_sizes': [16, 32, 64], 'fov_degrees': 180.0, 'calculation_method': 'steering_vector_optimization'}\n"
     ]
    }
   ],
   "source": [
    "data_path = \"../data/pretrain\"\n",
    "npz_files = list(Path(data_path).glob(\"*.npz\"))\n",
    "\n",
    "print(f\"Available datasets: {len(npz_files)} cities\")\n",
    "for file in sorted(npz_files):\n",
    "    file_size = file.stat().st_size / (1024*1024)  # MB\n",
    "    print(f\"  • {file.name}: {file_size:.1f} MB\")\n",
    "\n",
    "# Load one file to check data structure\n",
    "with np.load(npz_files[0], allow_pickle=True) as sample_data:\n",
    "    print(f\"\\nSample data structure from {npz_files[0].name}:\")\n",
    "    for key, value in sample_data.items():\n",
    "        if key == \"channels\":\n",
    "            print(f\"  • {key}: {value.shape} ({value.dtype})\")\n",
    "        else:\n",
    "            print(f\"  • {key}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Configuration Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'model': {'type': 'wimae',\n",
      "           'patch_size': [16, 1],\n",
      "           'encoder_dim': 64,\n",
      "           'encoder_layers': 2,\n",
      "           'encoder_nhead': 4,\n",
      "           'decoder_layers': 1,\n",
      "           'decoder_nhead': 2,\n",
      "           'mask_ratio': 0.9,\n",
      "           'contrastive_dim': 64,\n",
      "           'temperature': 0.2,\n",
      "           'snr_min': 5.0,\n",
      "           'snr_max': 40.0},\n",
      " 'data': {'data_dir': '../data/pretrain',\n",
      "          'normalize': True,\n",
      "          'val_split': 0.1,\n",
      "          'debug_size': None,\n",
      "          'calculate_statistics': True,\n",
      "          'statistics': {'real_mean': 0.021121172234416008,\n",
      "                         'real_std': 30.7452392578125,\n",
      "                         'imag_mean': -0.01027622725814581,\n",
      "                         'imag_std': 30.70543670654297}},\n",
      " 'training': {'batch_size': 64,\n",
      "              'epochs': 1,\n",
      "              'num_workers': 4,\n",
      "              'device': 'cpu',\n",
      "              'optimizer': {'type': 'adam',\n",
      "                            'lr': 0.0003,\n",
      "                            'weight_decay': 0.001,\n",
      "                            'betas': [0.9, 0.999]},\n",
      "              'scheduler': {'type': 'cosine', 'T_max': 3000, 'eta_min': 3e-06},\n",
      "              'loss': 'mse',\n",
      "              'patience': 5,\n",
      "              'min_delta': 0.0001,\n",
      "              'reconstruction_weight': 0.9,\n",
      "              'gradient_clip_val': 1.0,\n",
      "              'save_checkpoint_every_n': 10,\n",
      "              'save_best_only': True},\n",
      " 'logging': {'log_dir': 'runs',\n",
      "             'tensorboard': True,\n",
      "             'log_every_n_steps': 100,\n",
      "             'exp_name': 'demo_experiment'}}\n"
     ]
    }
   ],
   "source": [
    "config_path = \"../configs/default_training.yaml\"\n",
    "\n",
    "with open(config_path, 'r') as f:\n",
    "    config = yaml.safe_load(f)\n",
    "\n",
    "# Adjust config for demo (shorter training)\n",
    "config['model']['encoder_layers'] = 2\n",
    "config['model']['encoder_nhead'] = 4\n",
    "config['model']['decoder_layers'] = 1\n",
    "config['model']['decoder_nhead'] = 2\n",
    "config['model']['mask_ratio'] = 0.9\n",
    "\n",
    "config['training']['epochs'] = 1\n",
    "config['training']['batch_size'] = 64\n",
    "config['training']['device'] = \"cpu\"\n",
    "\n",
    "config['data']['data_dir'] = data_path\n",
    "\n",
    "config['logging']['exp_name'] = \"demo_experiment\"\n",
    "\n",
    "pprint.pprint(config, sort_dicts=False)\n",
    "\n",
    "# where to save checkpoints\n",
    "checkpoint_path = Path(f\"./{config['logging']['log_dir']}\") / f\"{config['model']['type']}_{config['logging']['exp_name']}\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### WiMAE Training Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting up WiMAE training...\n",
      "WiMAE trainer initialized\n",
      "WiMAE model created:\n",
      "  • model_type: WiMAE\n",
      "  • patch_size: (16, 1)\n",
      "  • encoder_dim: 64\n",
      "  • encoder_layers: 2\n",
      "  • encoder_nhead: 4\n",
      "  • decoder_layers: 1\n",
      "  • decoder_nhead: 2\n",
      "  • mask_ratio: 0.9\n",
      "  • total_parameters: 118992\n",
      "  • trainable_parameters: 118992\n"
     ]
    }
   ],
   "source": [
    "print(\"Setting up WiMAE training...\")\n",
    "\n",
    "# Create WiMAE trainer (model will be created during initialization)\n",
    "wimae_trainer = WiMAETrainer(config=config)\n",
    "\n",
    "print(\"WiMAE trainer initialized\")\n",
    "\n",
    "# Get model information\n",
    "wimae_info = wimae_trainer.model.get_model_info()\n",
    "print(f\"WiMAE model created:\")\n",
    "for key, value in wimae_info.items():\n",
    "    print(f\"  • {key}: {value}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  WiMAE Training Execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting WiMAE training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - Computing statistics from training dataset...\n",
      "INFO - Calculated statistics: {'real_mean': -0.06437671929597855, 'real_std': 26.93267822265625, 'imag_mean': -0.012862714007496834, 'imag_std': 26.949743270874023}\n",
      "INFO - Train samples: 32064\n",
      "INFO - Validation samples: 3562\n",
      "INFO - Starting training for 1 epochs...\n",
      "INFO - Model: wimae\n",
      "INFO - Device: cpu\n",
      "INFO - Log directory: runs/wimae_demo_experiment\n",
      "Training Epoch 0: 100%|██████████| 501/501 [00:12<00:00, 38.93it/s, loss=0.2823, avg_loss=0.8797]\n",
      "Validation: 100%|██████████| 56/56 [00:00<00:00, 187.02it/s]\n",
      "INFO - Epoch 0:\n",
      "INFO -   train_loss: 0.8797\n",
      "INFO -   val_loss: 0.8189\n",
      "INFO - Training completed!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WiMAE training completed successfully!\n"
     ]
    }
   ],
   "source": [
    "print(\"Starting WiMAE training...\")\n",
    "\n",
    "try:\n",
    "    # Start training (dataloaders will be set up automatically)\n",
    "    wimae_trainer.train()\n",
    "    print(\"WiMAE training completed successfully!\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Training failed: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Checkpoints and Model Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint Management\n",
      "==============================\n",
      "WiMAE checkpoints: 2\n",
      "  • last_checkpoint.pt\n",
      "  • best_checkpoint.pt\n"
     ]
    }
   ],
   "source": [
    "print(\"Checkpoint Management\")\n",
    "print(\"=\" * 30)\n",
    "\n",
    "# Check available checkpoints\n",
    "wimae_checkpoints = list(checkpoint_path.glob(\"*.pt\")) if checkpoint_path.exists() else []\n",
    "\n",
    "print(f\"WiMAE checkpoints: {len(wimae_checkpoints)}\")\n",
    "for ckpt in wimae_checkpoints:\n",
    "    print(f\"  • {ckpt.name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/berkay/Desktop/research/2025/WirelessContrastiveMaskedLearning/contrawimae/training/trainer.py:499: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(checkpoint_path, map_location=self.device)\n",
      "INFO - Loaded full training state from epoch 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Continuing training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - Computing statistics from training dataset...\n",
      "INFO - Calculated statistics: {'real_mean': -0.06437671929597855, 'real_std': 26.93267822265625, 'imag_mean': -0.012862714007496834, 'imag_std': 26.949743270874023}\n",
      "INFO - Train samples: 32064\n",
      "INFO - Validation samples: 3562\n",
      "INFO - Starting training for 1 epochs...\n",
      "INFO - Model: wimae\n",
      "INFO - Device: cpu\n",
      "INFO - Log directory: runs/wimae_demo_experiment\n",
      "Training Epoch 0: 100%|██████████| 501/501 [00:13<00:00, 35.82it/s, loss=0.4818, avg_loss=0.8368]\n",
      "Validation: 100%|██████████| 56/56 [00:00<00:00, 142.48it/s]\n",
      "INFO - Epoch 0:\n",
      "INFO -   train_loss: 0.8368\n",
      "INFO -   val_loss: 0.8116\n",
      "INFO - Training completed!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WiMAE training completed successfully!\n"
     ]
    }
   ],
   "source": [
    "# Example of loading a checkpoint into WiMAE\n",
    "best_checkpoint_path = checkpoint_path / \"best_checkpoint.pt\"\n",
    "wimae_trainer.load_checkpoint(best_checkpoint_path)\n",
    "\n",
    "\n",
    "# continue training\n",
    "print(\"Continuing training...\")\n",
    "\n",
    "try:\n",
    "    wimae_trainer.config[\"training\"][\"epochs\"] = 1\n",
    "    wimae_trainer.train()\n",
    "    print(\"WiMAE training completed successfully!\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Training failed: {e}\")()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ContraWiMAE Trainer Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING - Missing keys in checkpoint (will remain randomly initialized):\n",
      "WARNING -   - contrastive_head.proj_head.0.weight\n",
      "WARNING -   - contrastive_head.proj_head.0.bias\n",
      "WARNING -   - contrastive_head.proj_head.2.weight\n",
      "WARNING -   - contrastive_head.proj_head.2.bias\n",
      "INFO - Loaded model weights only (training state not restored)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting up ContraWiMAE training...\n",
      "ContraWiMAE trainer initialized\n",
      "ContraWiMAE model created:\n",
      "  • model_type: ContraWiMAE\n",
      "  • patch_size: (16, 1)\n",
      "  • encoder_dim: 64\n",
      "  • encoder_layers: 2\n",
      "  • encoder_nhead: 4\n",
      "  • decoder_layers: 1\n",
      "  • decoder_nhead: 2\n",
      "  • mask_ratio: 0.9\n",
      "  • total_parameters: 135568\n",
      "  • trainable_parameters: 135568\n",
      "  • contrastive_dim: 64\n",
      "  • temperature: 0.2\n",
      "  • snr_min: 5.0\n",
      "  • snr_max: 40.0\n"
     ]
    }
   ],
   "source": [
    "print(\"Setting up ContraWiMAE training...\")\n",
    "\n",
    "# adjust config for contra wimae\n",
    "config['model']['type'] = \"contrawimae\"\n",
    "\n",
    "# Create WiMAE trainer (model will be created during initialization)\n",
    "contra_wimae_trainer = ContraWiMAETrainer(config=config)\n",
    "\n",
    "# load wimae encoder and decoder weights\n",
    "# strict=False because we are not loading the contrastive head\n",
    "# model_only=True because we are not loading the training state\n",
    "contra_wimae_trainer.load_checkpoint(best_checkpoint_path, model_only=True, strict=False)\n",
    "\n",
    "print(\"ContraWiMAE trainer initialized\")\n",
    "\n",
    "# Get model information\n",
    "contra_wimae_info = contra_wimae_trainer.model.get_model_info()\n",
    "print(f\"ContraWiMAE model created:\")\n",
    "for key, value in contra_wimae_info.items():\n",
    "    print(f\"  • {key}: {value}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - Computing statistics from training dataset...\n",
      "INFO - Calculated statistics: {'real_mean': -0.06437671929597855, 'real_std': 26.93267822265625, 'imag_mean': -0.012862714007496834, 'imag_std': 26.949743270874023}\n",
      "INFO - Train samples: 32064\n",
      "INFO - Validation samples: 3562\n",
      "INFO - Starting training for 1 epochs...\n",
      "INFO - Model: contrawimae\n",
      "INFO - Device: cpu\n",
      "INFO - Log directory: runs/contrawimae_demo_experiment\n",
      "Training Epoch 0: 100%|██████████| 501/501 [00:23<00:00, 21.14it/s, recon_loss=0.7048, contrastive_loss=2.3269, total_loss=0.8670, avg_total_loss=1.0037]\n",
      "Validation: 100%|██████████| 56/56 [00:00<00:00, 75.00it/s]\n",
      "INFO - Epoch 0:\n",
      "INFO -   train_recon_loss: 0.8320\n",
      "INFO -   train_contrastive_loss: 2.5486\n",
      "INFO -   train_total_loss: 1.0037\n",
      "INFO -   val_recon_loss: 0.8120\n",
      "INFO -   val_contrastive_loss: 2.3479\n",
      "INFO -   val_loss: 0.9656\n",
      "INFO - Training completed!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ContraWiMAE training completed successfully!\n"
     ]
    }
   ],
   "source": [
    "# training contra wimae with wimae encoder and decoder weights\n",
    "contra_wimae_trainer.config[\"training\"][\"epochs\"] = 1\n",
    "contra_wimae_trainer.train()\n",
    "print(\"ContraWiMAE training completed successfully!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lwm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
