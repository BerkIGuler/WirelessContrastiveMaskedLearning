{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Demonstration for WiMAE and ContraWiMAE\n",
    "\n",
    "- This notebook demonstrates how to train both WiMAE and ContraWiMAE models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Imports and Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version: 2.5.1+cu121\n",
      "CUDA available: True\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import torch\n",
    "import numpy as np\n",
    "import yaml\n",
    "import pprint\n",
    "from pathlib import Path\n",
    "\n",
    "# For Jupyter notebooks\n",
    "sys.path.append(str(Path().cwd().parent))\n",
    "\n",
    "# WiMAE imports\n",
    "from contrawimae.training.train_wimae import WiMAETrainer\n",
    "from contrawimae.training.train_contramae import ContraWiMAETrainer\n",
    "\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available datasets: 12 cities\n",
      "  • city_0_newyork_channels.npz: 10.0 MB\n",
      "  • city_10_austin_channels.npz: 14.5 MB\n",
      "  • city_13_columbus_channels.npz: 11.2 MB\n",
      "  • city_17_seattle_channels.npz: 11.5 MB\n",
      "  • city_1_losangeles_channels.npz: 5.8 MB\n",
      "  • city_2_chicago_channels.npz: 2.2 MB\n",
      "  • city_3_houston_channels.npz: 20.1 MB\n",
      "  • city_4_phoenix_channels.npz: 21.1 MB\n",
      "  • city_5_philadelphia_channels.npz: 4.9 MB\n",
      "  • city_6_miami_channels.npz: 13.1 MB\n",
      "  • city_8_dallas_channels.npz: 19.6 MB\n",
      "  • city_9_sanfrancisco_channels.npz: 13.0 MB\n",
      "\n",
      "Sample data structure from city_0_newyork_channels.npz:\n",
      "  • channels: (1283, 1, 32, 32) (complex64)\n",
      "  • name: city_0_newyork\n",
      "  • n_rows: [ 0 44]\n",
      "  • n_per_row: 117\n",
      "  • active_bs: [1]\n",
      "  • n_ant_bs: 32\n",
      "  • n_ant_ue: 1\n",
      "  • n_subcarriers: 32\n",
      "  • scs: 30000.0\n",
      "  • data_folder: ./data/scenarios\n",
      "  • bs_rotation: [   0    0 -135]\n",
      "  • enable_bs2bs: False\n",
      "  • num_paths: 20\n"
     ]
    }
   ],
   "source": [
    "data_path = \"../data/pretrain\"\n",
    "npz_files = list(Path(data_path).glob(\"*.npz\"))\n",
    "\n",
    "print(f\"Available datasets: {len(npz_files)} cities\")\n",
    "for file in sorted(npz_files):\n",
    "    file_size = file.stat().st_size / (1024*1024)  # MB\n",
    "    print(f\"  • {file.name}: {file_size:.1f} MB\")\n",
    "\n",
    "# Load one file to check data structure\n",
    "with np.load(npz_files[0]) as sample_data:\n",
    "    print(f\"\\nSample data structure from {npz_files[0].name}:\")\n",
    "    for key, value in sample_data.items():\n",
    "        if key == \"channels\":\n",
    "            print(f\"  • {key}: {value.shape} ({value.dtype})\")\n",
    "        else:\n",
    "            print(f\"  • {key}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Configuration Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Default configuration loaded successfully:\n",
      "{'model': {'type': 'wimae',\n",
      "           'patch_size': [1, 16],\n",
      "           'encoder_dim': 64,\n",
      "           'encoder_layers': 12,\n",
      "           'encoder_nhead': 16,\n",
      "           'decoder_layers': 4,\n",
      "           'decoder_nhead': 8,\n",
      "           'mask_ratio': 0.6,\n",
      "           'contrastive_dim': 64,\n",
      "           'temperature': 0.1,\n",
      "           'snr_min': 0.0,\n",
      "           'snr_max': 30.0},\n",
      " 'data': {'data_dir': 'data/pretrain',\n",
      "          'normalize': True,\n",
      "          'val_split': 0.2,\n",
      "          'debug_size': None,\n",
      "          'calculate_statistics': True,\n",
      "          'statistics': {'real_mean': 0.021121172234416008,\n",
      "                         'real_std': 30.7452392578125,\n",
      "                         'imag_mean': -0.01027622725814581,\n",
      "                         'imag_std': 30.70543670654297}},\n",
      " 'training': {'batch_size': 64,\n",
      "              'epochs': 3000,\n",
      "              'num_workers': 4,\n",
      "              'device': 'cuda:0',\n",
      "              'optimizer': {'type': 'adam',\n",
      "                            'lr': 0.0003,\n",
      "                            'weight_decay': 0.0,\n",
      "                            'betas': [0.9, 0.999]},\n",
      "              'scheduler': {'type': 'cosine', 'T_max': 3000, 'eta_min': 3e-06},\n",
      "              'loss': 'mse',\n",
      "              'patience': 20,\n",
      "              'min_delta': 0.001,\n",
      "              'reconstruction_weight': 0.9,\n",
      "              'contrastive_weight': 0.1,\n",
      "              'gradient_clip_val': 1.0,\n",
      "              'save_checkpoint_every_n': 10,\n",
      "              'save_best_only': True},\n",
      " 'logging': {'log_dir': 'runs',\n",
      "             'tensorboard': True,\n",
      "             'log_every_n_steps': 100,\n",
      "             'exp_name': 'training_demo'}}\n",
      "\n",
      "Adjusted for demo:\n",
      "Encoder dim: 64\n",
      "Encoder layers: 2\n",
      "Encoder nhead: 4\n",
      "Decoder layers: 1\n",
      "Decoder nhead: 4\n",
      "Mask ratio: 0.6\n",
      "Epochs: 3\n",
      "Batch size: 768\n",
      "Device: cpu\n",
      "Data directory: ../data/pretrain\n",
      "Debug data size: 3840\n",
      "Experiment folder name: demo_exp\n"
     ]
    }
   ],
   "source": [
    "config_path = \"../configs/default_training.yaml\"\n",
    "\n",
    "with open(config_path, 'r') as f:\n",
    "    config = yaml.safe_load(f)\n",
    "\n",
    "print(\"Default configuration loaded successfully:\")\n",
    "pprint.pprint(config, sort_dicts=False)\n",
    "\n",
    "\n",
    "# Adjust config for demo (shorter training)\n",
    "config['model']['encoder_layers'] = 2\n",
    "config['model']['encoder_nhead'] = 4\n",
    "config['model']['decoder_layers'] = 1\n",
    "config['model']['decoder_nhead'] = 4\n",
    "config['model']['mask_ratio'] = 0.6\n",
    "\n",
    "config['training']['epochs'] = 3\n",
    "config['training']['batch_size'] = 768\n",
    "config['training']['device'] = \"cpu\"\n",
    "\n",
    "config['data']['data_dir'] = data_path\n",
    "config['data']['debug_size'] = config['training']['batch_size'] * 5\n",
    "\n",
    "config['logging']['exp_name'] = \"demo_exp\"\n",
    "\n",
    "print(f\"\\nAdjusted for demo:\")\n",
    "print(f\"Encoder dim: {config['model']['encoder_dim']}\")\n",
    "print(f\"Encoder layers: {config['model']['encoder_layers']}\")\n",
    "print(f\"Encoder nhead: {config['model']['encoder_nhead']}\")\n",
    "print(f\"Decoder layers: {config['model']['decoder_layers']}\")\n",
    "print(f\"Decoder nhead: {config['model']['decoder_nhead']}\")\n",
    "print(f\"Mask ratio: {config['model']['mask_ratio']}\")\n",
    "print(f\"Epochs: {config['training']['epochs']}\")\n",
    "print(f\"Batch size: {config['training']['batch_size']}\")\n",
    "print(f\"Device: {config['training']['device']}\")\n",
    "print(f\"Data directory: {config['data']['data_dir']}\")\n",
    "print(f\"Debug data size: {config['data']['debug_size']}\")\n",
    "print(f\"Experiment folder name: {config['logging']['exp_name']}\")\n",
    "\n",
    "# where to save checkpoints\n",
    "checkpoint_path = Path(f\"./{config['logging']['log_dir']}\") / f\"{config['model']['type']}_{config['logging']['exp_name']}\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### WiMAE Training Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting up WiMAE training...\n",
      "WiMAE trainer initialized\n",
      "WiMAE model created:\n",
      "  • model_type: WiMAE\n",
      "  • patch_size: (1, 16)\n",
      "  • encoder_dim: 64\n",
      "  • encoder_layers: 2\n",
      "  • encoder_nhead: 4\n",
      "  • decoder_layers: 1\n",
      "  • decoder_nhead: 4\n",
      "  • mask_ratio: 0.6\n",
      "  • total_parameters: 118992\n",
      "  • trainable_parameters: 118992\n"
     ]
    }
   ],
   "source": [
    "print(\"Setting up WiMAE training...\")\n",
    "\n",
    "# Create WiMAE trainer (model will be created during initialization)\n",
    "wimae_trainer = WiMAETrainer(config=config)\n",
    "\n",
    "print(\"WiMAE trainer initialized\")\n",
    "\n",
    "# Get model information\n",
    "wimae_info = wimae_trainer.model.get_model_info()\n",
    "print(f\"WiMAE model created:\")\n",
    "for key, value in wimae_info.items():\n",
    "    print(f\"  • {key}: {value}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  WiMAE Training Execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting WiMAE training...\n",
      "Total samples: 18824, dimensions: 32x32\n",
      "Loading file 1/12: city_0_newyork_channels.npz\n",
      "Loading file 2/12: city_1_losangeles_channels.npz\n",
      "Loading file 3/12: city_10_austin_channels.npz\n",
      "Loading file 4/12: city_9_sanfrancisco_channels.npz\n",
      "Loading file 5/12: city_6_miami_channels.npz\n",
      "Loading file 6/12: city_13_columbus_channels.npz\n",
      "Loading file 7/12: city_2_chicago_channels.npz\n",
      "Loading file 8/12: city_5_philadelphia_channels.npz\n",
      "Loading file 9/12: city_17_seattle_channels.npz\n",
      "Loading file 10/12: city_3_houston_channels.npz\n",
      "Loading file 11/12: city_8_dallas_channels.npz\n",
      "Loading file 12/12: city_4_phoenix_channels.npz\n",
      "Successfully loaded all 18824 samples\n",
      "Computing statistics from training dataset...\n",
      "Calculated statistics: {'real_mean': 0.0013652583584189415, 'real_std': 30.900094985961914, 'imag_mean': -0.0803627148270607, 'imag_std': 30.591354370117188}\n",
      "Total samples: 18824, dimensions: 32x32\n",
      "Loading file 1/12: city_0_newyork_channels.npz\n",
      "Loading file 2/12: city_1_losangeles_channels.npz\n",
      "Loading file 3/12: city_10_austin_channels.npz\n",
      "Loading file 4/12: city_9_sanfrancisco_channels.npz\n",
      "Loading file 5/12: city_6_miami_channels.npz\n",
      "Loading file 6/12: city_13_columbus_channels.npz\n",
      "Loading file 7/12: city_2_chicago_channels.npz\n",
      "Loading file 8/12: city_5_philadelphia_channels.npz\n",
      "Loading file 9/12: city_17_seattle_channels.npz\n",
      "Loading file 10/12: city_3_houston_channels.npz\n",
      "Loading file 11/12: city_8_dallas_channels.npz\n",
      "Loading file 12/12: city_4_phoenix_channels.npz\n",
      "Successfully loaded all 18824 samples\n",
      "Train samples: 3072\n",
      "Validation samples: 768\n",
      "Starting training for 3 epochs...\n",
      "Model: wimae\n",
      "Device: cpu\n",
      "Log directory: runs/wimae_demo_exp\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 0: 100%|██████████| 4/4 [00:02<00:00,  1.42it/s, loss=1.2166, avg_loss=1.1771]\n",
      "Validation: 100%|██████████| 1/1 [00:00<00:00,  2.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:\n",
      "  train_loss: 1.1771\n",
      "  val_masked_loss: 1.1310\n",
      "  val_full_loss: 1.2507\n",
      "  val_loss: 1.1310\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 1: 100%|██████████| 4/4 [00:02<00:00,  1.42it/s, loss=1.0080, avg_loss=1.0571]\n",
      "Validation: 100%|██████████| 1/1 [00:00<00:00,  4.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1:\n",
      "  train_loss: 1.0571\n",
      "  val_masked_loss: 1.1170\n",
      "  val_full_loss: 1.2334\n",
      "  val_loss: 1.1170\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 2: 100%|██████████| 4/4 [00:02<00:00,  1.46it/s, loss=0.8479, avg_loss=1.0528]\n",
      "Validation: 100%|██████████| 1/1 [00:00<00:00,  3.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2:\n",
      "  train_loss: 1.0528\n",
      "  val_masked_loss: 1.1000\n",
      "  val_full_loss: 1.2167\n",
      "  val_loss: 1.1000\n",
      "Training completed!\n",
      "WiMAE training completed successfully!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Starting WiMAE training...\")\n",
    "\n",
    "try:\n",
    "    # Start training (dataloaders will be set up automatically)\n",
    "    wimae_trainer.train()\n",
    "    print(\"WiMAE training completed successfully!\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Training failed: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Checkpoints and Model Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint Management\n",
      "==============================\n",
      "WiMAE checkpoints: 2\n",
      "  • last_checkpoint.pt\n",
      "  • best_checkpoint.pt\n"
     ]
    }
   ],
   "source": [
    "print(\"Checkpoint Management\")\n",
    "print(\"=\" * 30)\n",
    "\n",
    "# Check available checkpoints\n",
    "wimae_checkpoints = list(checkpoint_path.glob(\"*.pt\")) if checkpoint_path.exists() else []\n",
    "\n",
    "print(f\"WiMAE checkpoints: {len(wimae_checkpoints)}\")\n",
    "for ckpt in wimae_checkpoints:\n",
    "    print(f\"  • {ckpt.name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/berkay/Desktop/research/2025/WirelessContrastiveMaskedLearning/wimae/training/trainer.py:424: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(checkpoint_path, map_location=self.device)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded full training state from epoch 2\n",
      "Continuing training...\n",
      "Total samples: 18824, dimensions: 32x32\n",
      "Loading file 1/12: city_0_newyork_channels.npz\n",
      "Loading file 2/12: city_1_losangeles_channels.npz\n",
      "Loading file 3/12: city_10_austin_channels.npz\n",
      "Loading file 4/12: city_9_sanfrancisco_channels.npz\n",
      "Loading file 5/12: city_6_miami_channels.npz\n",
      "Loading file 6/12: city_13_columbus_channels.npz\n",
      "Loading file 7/12: city_2_chicago_channels.npz\n",
      "Loading file 8/12: city_5_philadelphia_channels.npz\n",
      "Loading file 9/12: city_17_seattle_channels.npz\n",
      "Loading file 10/12: city_3_houston_channels.npz\n",
      "Loading file 11/12: city_8_dallas_channels.npz\n",
      "Loading file 12/12: city_4_phoenix_channels.npz\n",
      "Successfully loaded all 18824 samples\n",
      "Computing statistics from training dataset...\n",
      "Calculated statistics: {'real_mean': 0.0013652583584189415, 'real_std': 30.900094985961914, 'imag_mean': -0.0803627148270607, 'imag_std': 30.591354370117188}\n",
      "Total samples: 18824, dimensions: 32x32\n",
      "Loading file 1/12: city_0_newyork_channels.npz\n",
      "Loading file 2/12: city_1_losangeles_channels.npz\n",
      "Loading file 3/12: city_10_austin_channels.npz\n",
      "Loading file 4/12: city_9_sanfrancisco_channels.npz\n",
      "Loading file 5/12: city_6_miami_channels.npz\n",
      "Loading file 6/12: city_13_columbus_channels.npz\n",
      "Loading file 7/12: city_2_chicago_channels.npz\n",
      "Loading file 8/12: city_5_philadelphia_channels.npz\n",
      "Loading file 9/12: city_17_seattle_channels.npz\n",
      "Loading file 10/12: city_3_houston_channels.npz\n",
      "Loading file 11/12: city_8_dallas_channels.npz\n",
      "Loading file 12/12: city_4_phoenix_channels.npz\n",
      "Successfully loaded all 18824 samples\n",
      "Train samples: 3072\n",
      "Validation samples: 768\n",
      "Starting training for 10 epochs...\n",
      "Model: wimae\n",
      "Device: cpu\n",
      "Log directory: runs/wimae_demo_exp\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 2: 100%|██████████| 4/4 [00:02<00:00,  1.36it/s, loss=1.0797, avg_loss=1.0401]\n",
      "Validation: 100%|██████████| 1/1 [00:00<00:00,  2.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2:\n",
      "  train_loss: 1.0401\n",
      "  val_masked_loss: 1.0922\n",
      "  val_full_loss: 1.2120\n",
      "  val_loss: 1.0922\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 3: 100%|██████████| 4/4 [00:02<00:00,  1.39it/s, loss=1.2286, avg_loss=1.0374]\n",
      "Validation: 100%|██████████| 1/1 [00:00<00:00,  3.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3:\n",
      "  train_loss: 1.0374\n",
      "  val_masked_loss: 1.1004\n",
      "  val_full_loss: 1.2109\n",
      "  val_loss: 1.1004\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 4: 100%|██████████| 4/4 [00:02<00:00,  1.43it/s, loss=0.9134, avg_loss=1.0327]\n",
      "Validation: 100%|██████████| 1/1 [00:00<00:00,  3.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4:\n",
      "  train_loss: 1.0327\n",
      "  val_masked_loss: 1.0929\n",
      "  val_full_loss: 1.2077\n",
      "  val_loss: 1.0929\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 5: 100%|██████████| 4/4 [00:02<00:00,  1.42it/s, loss=1.0557, avg_loss=1.0312]\n",
      "Validation: 100%|██████████| 1/1 [00:00<00:00,  3.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5:\n",
      "  train_loss: 1.0312\n",
      "  val_masked_loss: 1.0931\n",
      "  val_full_loss: 1.2038\n",
      "  val_loss: 1.0931\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 6: 100%|██████████| 4/4 [00:02<00:00,  1.42it/s, loss=0.8846, avg_loss=1.0295]\n",
      "Validation: 100%|██████████| 1/1 [00:00<00:00,  3.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6:\n",
      "  train_loss: 1.0295\n",
      "  val_masked_loss: 1.0871\n",
      "  val_full_loss: 1.2013\n",
      "  val_loss: 1.0871\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 7: 100%|██████████| 4/4 [00:02<00:00,  1.43it/s, loss=1.0135, avg_loss=1.0180]\n",
      "Validation: 100%|██████████| 1/1 [00:00<00:00,  4.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7:\n",
      "  train_loss: 1.0180\n",
      "  val_masked_loss: 1.0911\n",
      "  val_full_loss: 1.1994\n",
      "  val_loss: 1.0911\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 8: 100%|██████████| 4/4 [00:02<00:00,  1.47it/s, loss=1.0084, avg_loss=1.0222]\n",
      "Validation: 100%|██████████| 1/1 [00:00<00:00,  3.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8:\n",
      "  train_loss: 1.0222\n",
      "  val_masked_loss: 1.0857\n",
      "  val_full_loss: 1.1986\n",
      "  val_loss: 1.0857\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 9: 100%|██████████| 4/4 [00:02<00:00,  1.36it/s, loss=1.0364, avg_loss=1.0229]\n",
      "Validation: 100%|██████████| 1/1 [00:00<00:00,  3.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9:\n",
      "  train_loss: 1.0229\n",
      "  val_masked_loss: 1.0953\n",
      "  val_full_loss: 1.1970\n",
      "  val_loss: 1.0953\n",
      "Training completed!\n",
      "WiMAE training completed successfully!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Example of loading a checkpoint into WiMAE\n",
    "best_checkpoint_path = checkpoint_path / \"best_checkpoint.pt\"\n",
    "wimae_trainer.load_checkpoint(best_checkpoint_path)\n",
    "\n",
    "\n",
    "# continue training\n",
    "print(\"Continuing training...\")\n",
    "\n",
    "try:\n",
    "    wimae_trainer.config[\"training\"][\"epochs\"] = 10\n",
    "    wimae_trainer.train()\n",
    "    print(\"WiMAE training completed successfully!\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Training failed: {e}\")()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ContraWiMAE Trainer Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting up ContraWiMAE training...\n",
      "Warning: Missing keys in checkpoint (will remain randomly initialized):\n",
      "  - contrastive_head.proj_head.0.weight\n",
      "  - contrastive_head.proj_head.0.bias\n",
      "  - contrastive_head.proj_head.2.weight\n",
      "  - contrastive_head.proj_head.2.bias\n",
      "Loaded model weights only (training state not restored)\n",
      "ContraWiMAE trainer initialized\n",
      "ContraWiMAE model created:\n",
      "  • model_type: ContraWiMAE\n",
      "  • patch_size: (1, 16)\n",
      "  • encoder_dim: 64\n",
      "  • encoder_layers: 2\n",
      "  • encoder_nhead: 4\n",
      "  • decoder_layers: 1\n",
      "  • decoder_nhead: 4\n",
      "  • mask_ratio: 0.6\n",
      "  • total_parameters: 135568\n",
      "  • trainable_parameters: 135568\n",
      "  • contrastive_dim: 64\n",
      "  • temperature: 0.1\n",
      "  • snr_min: 0.0\n",
      "  • snr_max: 30.0\n"
     ]
    }
   ],
   "source": [
    "print(\"Setting up ContraWiMAE training...\")\n",
    "\n",
    "# adjust config for contra wimae\n",
    "config['model']['type'] = \"contrawimae\"\n",
    "\n",
    "# Create WiMAE trainer (model will be created during initialization)\n",
    "contra_wimae_trainer = ContraWiMAETrainer(config=config)\n",
    "\n",
    "# load wimae encoder and decoder weights\n",
    "# strict=False because we are not loading the contrastive head\n",
    "# model_only=True because we are not loading the training state\n",
    "contra_wimae_trainer.load_checkpoint(best_checkpoint_path, model_only=True, strict=False)\n",
    "\n",
    "print(\"ContraWiMAE trainer initialized\")\n",
    "\n",
    "# Get model information\n",
    "contra_wimae_info = contra_wimae_trainer.model.get_model_info()\n",
    "print(f\"ContraWiMAE model created:\")\n",
    "for key, value in contra_wimae_info.items():\n",
    "    print(f\"  • {key}: {value}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total samples: 18824, dimensions: 32x32\n",
      "Loading file 1/12: city_0_newyork_channels.npz\n",
      "Loading file 2/12: city_1_losangeles_channels.npz\n",
      "Loading file 3/12: city_10_austin_channels.npz\n",
      "Loading file 4/12: city_9_sanfrancisco_channels.npz\n",
      "Loading file 5/12: city_6_miami_channels.npz\n",
      "Loading file 6/12: city_13_columbus_channels.npz\n",
      "Loading file 7/12: city_2_chicago_channels.npz\n",
      "Loading file 8/12: city_5_philadelphia_channels.npz\n",
      "Loading file 9/12: city_17_seattle_channels.npz\n",
      "Loading file 10/12: city_3_houston_channels.npz\n",
      "Loading file 11/12: city_8_dallas_channels.npz\n",
      "Loading file 12/12: city_4_phoenix_channels.npz\n",
      "Successfully loaded all 18824 samples\n",
      "Computing statistics from training dataset...\n",
      "Calculated statistics: {'real_mean': 0.0013652583584189415, 'real_std': 30.900094985961914, 'imag_mean': -0.0803627148270607, 'imag_std': 30.591354370117188}\n",
      "Total samples: 18824, dimensions: 32x32\n",
      "Loading file 1/12: city_0_newyork_channels.npz\n",
      "Loading file 2/12: city_1_losangeles_channels.npz\n",
      "Loading file 3/12: city_10_austin_channels.npz\n",
      "Loading file 4/12: city_9_sanfrancisco_channels.npz\n",
      "Loading file 5/12: city_6_miami_channels.npz\n",
      "Loading file 6/12: city_13_columbus_channels.npz\n",
      "Loading file 7/12: city_2_chicago_channels.npz\n",
      "Loading file 8/12: city_5_philadelphia_channels.npz\n",
      "Loading file 9/12: city_17_seattle_channels.npz\n",
      "Loading file 10/12: city_3_houston_channels.npz\n",
      "Loading file 11/12: city_8_dallas_channels.npz\n",
      "Loading file 12/12: city_4_phoenix_channels.npz\n",
      "Successfully loaded all 18824 samples\n",
      "Train samples: 3072\n",
      "Validation samples: 768\n",
      "Starting training for 5 epochs...\n",
      "Model: contramae\n",
      "Device: cpu\n",
      "Log directory: runs/contramae_demo_exp\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 0: 100%|██████████| 4/4 [00:04<00:00,  1.21s/it, recon_loss=0.8723, contrastive_loss=6.8901, total_loss=1.4741, avg_total_loss=1.6252]\n",
      "Validation: 100%|██████████| 1/1 [00:00<00:00,  1.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:\n",
      "  train_recon_loss: 1.0233\n",
      "  train_contrastive_loss: 7.0419\n",
      "  train_total_loss: 1.6252\n",
      "  val_masked_recon_loss: 1.0880\n",
      "  val_full_recon_loss: 1.2089\n",
      "  val_contrastive_loss: 6.7856\n",
      "  val_masked_loss: 1.6578\n",
      "  val_full_loss: 1.7666\n",
      "  val_loss: 1.6578\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 1: 100%|██████████| 4/4 [00:05<00:00,  1.34s/it, recon_loss=1.0353, contrastive_loss=6.4769, total_loss=1.5794, avg_total_loss=1.5819]\n",
      "Validation: 100%|██████████| 1/1 [00:00<00:00,  1.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1:\n",
      "  train_recon_loss: 1.0226\n",
      "  train_contrastive_loss: 6.6157\n",
      "  train_total_loss: 1.5819\n",
      "  val_masked_recon_loss: 1.0980\n",
      "  val_full_recon_loss: 1.2098\n",
      "  val_contrastive_loss: 6.3382\n",
      "  val_masked_loss: 1.6220\n",
      "  val_full_loss: 1.7227\n",
      "  val_loss: 1.6220\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 2: 100%|██████████| 4/4 [00:04<00:00,  1.24s/it, recon_loss=0.9224, contrastive_loss=6.2361, total_loss=1.4538, avg_total_loss=1.5478]\n",
      "Validation: 100%|██████████| 1/1 [00:00<00:00,  1.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2:\n",
      "  train_recon_loss: 1.0204\n",
      "  train_contrastive_loss: 6.2942\n",
      "  train_total_loss: 1.5478\n",
      "  val_masked_recon_loss: 1.0902\n",
      "  val_full_recon_loss: 1.2053\n",
      "  val_contrastive_loss: 6.1315\n",
      "  val_masked_loss: 1.5943\n",
      "  val_full_loss: 1.6979\n",
      "  val_loss: 1.5943\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 3: 100%|██████████| 4/4 [00:04<00:00,  1.23s/it, recon_loss=1.0305, contrastive_loss=6.0666, total_loss=1.5341, avg_total_loss=1.5263]\n",
      "Validation: 100%|██████████| 1/1 [00:00<00:00,  1.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3:\n",
      "  train_recon_loss: 1.0149\n",
      "  train_contrastive_loss: 6.1283\n",
      "  train_total_loss: 1.5263\n",
      "  val_masked_recon_loss: 1.0943\n",
      "  val_full_recon_loss: 1.1994\n",
      "  val_contrastive_loss: 5.9995\n",
      "  val_masked_loss: 1.5848\n",
      "  val_full_loss: 1.6794\n",
      "  val_loss: 1.5848\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 4: 100%|██████████| 4/4 [00:04<00:00,  1.19s/it, recon_loss=1.0315, contrastive_loss=5.9764, total_loss=1.5260, avg_total_loss=1.5172]\n",
      "Validation: 100%|██████████| 1/1 [00:00<00:00,  1.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4:\n",
      "  train_recon_loss: 1.0180\n",
      "  train_contrastive_loss: 6.0101\n",
      "  train_total_loss: 1.5172\n",
      "  val_masked_recon_loss: 1.0965\n",
      "  val_full_recon_loss: 1.1957\n",
      "  val_contrastive_loss: 5.9016\n",
      "  val_masked_loss: 1.5770\n",
      "  val_full_loss: 1.6663\n",
      "  val_loss: 1.5770\n",
      "Training completed!\n",
      "ContraWiMAE training completed successfully!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# training contra wimae with wimae encoder and decoder weights\n",
    "contra_wimae_trainer.config[\"training\"][\"epochs\"] = 5\n",
    "contra_wimae_trainer.train()\n",
    "print(\"ContraWiMAE training completed successfully!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lwm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
